{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0540710-cda5-4b06-85f3-cbc346a41912",
   "metadata": {},
   "source": [
    "# 4. Shortest paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07422f2b-5d5b-48e5-b465-8a99b5cb1ec3",
   "metadata": {},
   "source": [
    "**This file is used to prepare the final table from \"table_graph\" and then to build the algorithm to find the shortest path.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df54a39-11b4-4923-967d-88e58d2fb617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from math import cos, sin, pi, sqrt, atan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f132cfe-7da8-4fb0-90af-c79bf846b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git lfs pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d166aed-c085-46df-962b-9e74bd089ec0",
   "metadata": {},
   "source": [
    "## 4.1. Build df_public_transp from table_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed3fd4-fadd-4cee-be1a-04b3d450fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the table for the graph \n",
    "table_graph = pd.read_csv('../data/table_graph.csv')\n",
    "table_graph.columns = table_graph.columns.str[12:]\n",
    "table_graph.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff16222-0cff-4409-8437-bca31cb30db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column types\n",
    "table_graph = table_graph.astype({'stop_sequence':int})\n",
    "table_graph['arrival_time'] = table_graph['arrival_time'].apply(lambda x: dt.datetime.strptime(x, '%H:%M:%S'))\n",
    "table_graph['departure_time'] = table_graph['departure_time'].apply(lambda x: dt.datetime.strptime(x, '%H:%M:%S'))\n",
    "table_graph.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe58a32-991e-4f2c-956f-172e525369f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7b6e73-b0c8-47be-9f30-d2b9893c4f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and adjust table_graph\n",
    "\n",
    "table_graph = table_graph.dropna(subset = ['trip_id'])\n",
    "table_graph = table_graph[table_graph[\"stop_id\"].str.contains(\"Parent\")==False]\n",
    "table_graph['stop_id'] = table_graph['stop_id'].str[:7]\n",
    "table_graph = table_graph.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "table_graph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3cc2a7-84d1-4530-988e-2554688ef26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataframe with public transport to do the graph after\n",
    "\n",
    "# empty table to fill with the edges\n",
    "name_src = list(table_graph.add_prefix('src_').columns)\n",
    "name_dst = list(table_graph.add_prefix('dst_').columns)\n",
    "df_public_transp = pd.DataFrame(columns = name_src+name_dst+['duration'])\n",
    "\n",
    "# find edges\n",
    "for key, df_trip in table_graph.groupby(['trip_id']):\n",
    "    \n",
    "    df_trip = df_trip.drop_duplicates()\n",
    "    \n",
    "    if df_trip.empty or len(df_trip) == 1:\n",
    "        continue\n",
    "\n",
    "    df_trip = df_trip.sort_values(by=\"stop_sequence\")\n",
    "    sequence_pairs = zip(df_trip.stop_sequence.values[:-1], df_trip.stop_sequence.values[1:])\n",
    "    \n",
    "    for seq1,seq2 in sequence_pairs:\n",
    "        df_src = df_trip[df_trip.stop_sequence==seq1].reset_index(drop=True)\n",
    "        df_dst = df_trip[df_trip.stop_sequence==seq2].reset_index(drop=True)\n",
    "        \n",
    "        df_src_dst = pd.concat([df_src.add_prefix('src_'), df_dst.add_prefix('dst_')], axis=1)\n",
    "        df_src_dst['duration'] = df_src_dst.dst_arrival_time - df_src_dst.src_departure_time\n",
    "        df_src_dst['duration'] = df_src_dst['duration'].apply(lambda x: int(x.seconds/60))\n",
    "\n",
    "        df_public_transp = pd.concat([df_public_transp, df_src_dst], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02dc1ee-ae01-4878-83e9-9818ba955df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter non useful columns\n",
    "df_public_transp.drop(columns=['dst_monday', 'dst_tuesday', 'dst_wednesday', 'dst_thursday', 'dst_friday', 'dst_vehicule'], inplace=True)\n",
    "df_public_transp.rename(columns={\"src_monday\": \"monday\", \"src_tuesday\": \"tuesday\", \"src_wednesday\": \"wednesday\", \"src_thursday\": \"thursday\", \"src_friday\": \"friday\", \"src_vehicule\": \"vehicule\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ed92b-8174-43b8-b014-29c510cbace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_public_transp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc058622-675d-4c03-b227-8d4aae332137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "df_public_transp.to_csv('../data/public_transp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade79d8-725a-4cda-89a5-0adb7acd1af7",
   "metadata": {},
   "source": [
    "## 4.2. Add walking edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2f5825-0449-4a21-86a3-6d167ead4d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the table of all filtered nodes\n",
    "table_stops = pd.read_csv('../data/stops.csv')\n",
    "table_stops.columns = table_stops.columns.str[15:]\n",
    "table_stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a624b3d-d913-4ab3-a167-e597a83d7346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find tuples of node for walking edges\n",
    "\n",
    "p = pi/180 #F.radians\n",
    "v = 50e-3\n",
    "\n",
    "R = 6371 # Earth's radius in km\n",
    "\n",
    "walking_nodes = []\n",
    "\n",
    "for i, row_stop1 in table_stops.iterrows():\n",
    "    for j, row_stop2 in table_stops.iterrows():\n",
    "        \n",
    "        stop_id_1 = row_stop1.stop_id\n",
    "        stop_id_2 = row_stop2.stop_id\n",
    "\n",
    "        lat1, lon1 = p*row_stop1.stop_lat, p*row_stop1.stop_lon\n",
    "        lat2, lon2 = p*row_stop2.stop_lat, p*row_stop2.stop_lon\n",
    "\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "        c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "        distance = R * c  \n",
    "\n",
    "        if (distance<0.5) & (stop_id_1!=stop_id_2):\n",
    "            #for departure_time in range(60*6,60*18):\n",
    "            walking_nodes.append((stop_id_1, stop_id_2, 0, distance/v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32e041f-e011-4359-82a3-97f09e66f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add walking edges to a dataframe\n",
    "df_walking = pd.DataFrame(walking_nodes, columns=['src_stop_id','dst_stop_id','src_departure_time','duration'])\n",
    "df_walking['src_trip_id'] = 'foot'\n",
    "df_walking['vehicule'] = 'foot'\n",
    "df_walking[\"duration\"] = df_walking[\"duration\"].apply(lambda x: int(x))\n",
    "\n",
    "df_walking = df_walking.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1cc543-18b7-4a24-8e47-bc6fd08bba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf677f-5ab0-4dd4-b765-0dd3d01e7c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only stops that do not have parents i.e. is a Parent\n",
    "df_walking_small = df_walking[df_walking[\"src_stop_id\"].str.contains(\"Parent\")==False]\n",
    "df_walking_small = df_walking_small[df_walking_small[\"dst_stop_id\"].str.contains(\"Parent\")==False]\n",
    "\n",
    "# Leave out the platform information: keep only the stop_id for each stop\n",
    "df_walking_small['dst_stop_id'] = df_walking_small['dst_stop_id'].str[:7]\n",
    "df_walking_small['src_stop_id'] = df_walking_small['src_stop_id'].str[:7]\n",
    "\n",
    "# Drop duplicate edges \n",
    "df_walking_small = df_walking_small.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d39cef7-4f99-4d8d-a6e3-d2211e5a79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "df_walking_small.to_csv('../data/walk_small.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5789710-787f-4114-a073-a9983bc2ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time (intervall of 1 min)\n",
    "timestamps = pd.date_range(start=dt.datetime.strptime('05:00:00', '%H:%M:%S'), end=dt.datetime.strptime('23:00:00', '%H:%M:%S'), freq='min')\n",
    "df_walking_small['src_departure_time'] = [timestamps.tolist() for _ in range(len(df_walking_small))]\n",
    "df_walking_edges = df_walking_small.explode('src_departure_time')\n",
    "df_walking_edges['dst_arrival_time'] = df_walking_edges.apply(lambda row: row['src_departure_time'] + pd.to_timedelta(row['duration'], unit='minutes'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e8ee64-462a-4f04-b283-5f7fdbc13a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add days\n",
    "days = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday']\n",
    "for col in days:\n",
    "    df_walking_edges[col] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e364b-c4a6-4825-8610-e1938c710f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_walking_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6945264a-783d-4f2c-91fe-a20dd6e766f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "df_walking_edges.to_csv('../data/walk_edges.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cc4855-7151-4d3d-bcf6-9801b3b4c0ea",
   "metadata": {},
   "source": [
    "## 4.3. Merge to get df_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24af20d5-eb5f-490a-b756-88d02d6d6f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_public_transp and df_walking_edges in a final graph\n",
    "df_graph = pd.concat([df_public_transp, df_walking_edges], ignore_index=True)\n",
    "df_graph.drop(columns=['src_arrival_time', 'src_stop_sequence', 'src_direction_id', 'dst_trip_id', 'dst_departure_time', 'dst_stop_sequence', 'dst_direction_id'], inplace=True)\n",
    "df_graph.rename(columns={\"src_trip_id\": \"trip_id\"}, inplace=True)\n",
    "df_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea28d40-8552-4f05-a1df-8f93040e810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "df_graph.to_csv('../data/all_edges.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e527c82d-9c60-49ca-8051-abcb4fddb34f",
   "metadata": {},
   "source": [
    "## 4.4. Testing routing algorithm and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a428f6-f108-493f-9046-387c5ffde6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE INPUTS\n",
    "TRAVEL_DAY = 'monday'\n",
    "ARRIVAL_TIME = '12:43:00'\n",
    "PROBA_THRESHOLD = 0.95\n",
    "DEPARTURE = '8503104'\n",
    "DESTINATION = '8503000'\n",
    "EARLIEST_DEPARTURE_TIME = '07:20:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ba43d-ef9c-4ff3-8e2c-76ad5df055e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARRIVAL_TIME = dt.datetime.strptime(ARRIVAL_TIME, '%H:%M:%S')\n",
    "EARLIEST_DEPARTURE_TIME = dt.datetime.strptime(EARLIEST_DEPARTURE_TIME, '%H:%M:%S')\n",
    "table_graph = table_graph.loc[(table_graph[TRAVEL_DAY]==1) & (table_graph['arrival_time']<=ARRIVAL_TIME)  & (table_graph['departure_time']>=EARLIEST_DEPARTURE_TIME)].copy() \n",
    "table_graph.drop(columns=['monday', 'tuesday', 'wednesday', 'thursday', 'friday'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5942ac57-a5d4-4b6a-a7e5-26691a11cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#routing algorithm\n",
    "def routing(df_graph, arrival_stop_id, arrival_time, proba_threshold):\n",
    "    \n",
    "    df_graph.sort_values(by=['src_departure_time'], ascending=False, inplace=True) # ordering the edges in descending order according to their starting time\n",
    "    \n",
    "    transfer_time = dt.timedelta(minutes=2) # minimal transfer time between two different transports at the same location\n",
    "    distinct_stops = pd.concat([df_graph['src_stop_id'],df_graph['dst_stop_id']]).unique() # retrieving the nodes of the graph from the edges\n",
    "    path = dict()  # dict that takes as key a departure stop_id and as value a list [departure_time, arrival_time, arrival stop_id, transport_ID, proba_sucess, transport mode]\n",
    "    \n",
    "    ### 1. Put default list for each stop ###\n",
    "    \n",
    "    for stop_id in distinct_stops:\n",
    "        \n",
    "        if (stop_id == arrival_stop_id):\n",
    "            path[stop_id] = [arrival_time, arrival_time, arrival_stop_id, None, 1, None]\n",
    "       \n",
    "        else:\n",
    "            path[stop_id] = [dt.datetime.strptime('00:00:01', '%H:%M:%S'), dt.datetime.strptime('00:00:01', '%H:%M:%S'), None, None, None, None]   \n",
    "            \n",
    "    ### 2. Scans each edge to update the list of each stop ###\n",
    "    \n",
    "    progress_bar = tqdm(total=len(df_graph), desc='Processing', unit='iteration')\n",
    "    for i, edge in df_graph.iterrows():\n",
    "        \n",
    "        u = edge['src_stop_id']  # stop_id of departure\n",
    "        v = edge['dst_stop_id']  # stop_id of arrival\n",
    "        t = edge['src_departure_time']  # instant of departure\n",
    "        delta = dt.timedelta(minutes=edge['duration'])  # duration of the journey\n",
    "        trip_id = edge['trip_id']  # trip_id\n",
    "        vehicule = edge['vehicule']  # vehicule\n",
    "        transfer_time = dt.timedelta(minutes=2) #redefined here since it might become 0 if we walk or we do not change transport type cf. what follows\n",
    "        \n",
    "        if ((trip_id == path[v][3]) or (vehicule=='foot')):  # checking if the transport ID of the edge (connection) is the same as the one we are taking afterwards (from v) \n",
    "            transfer_time = dt.timedelta(minutes=0)  # no transfer time between two same transport id\n",
    "            if ((t + delta) <= path[v][0]):  # checking if the connection makes us arrive at stop v before the next transport departs from stop v\n",
    "                if (t > path[u][0]):  # updating the path only if the connection makes us depart from u later (we want the latest departure time)\n",
    "                    path[u][0] = t \n",
    "                    path[u][1] = t + delta\n",
    "                    path[u][2] = v\n",
    "                    path[u][3] = trip_id\n",
    "                    path[u][4] = path[v][4]\n",
    "                    path[u][5] = vehicule\n",
    "\n",
    "        else :  # changing transport ID\n",
    "            if v == arrival_stop_id: # no need to add transfer time if we arrive at the final destination\n",
    "                transfer_time = dt.timedelta(minutes=0)\n",
    "     \n",
    "            if ((t + delta + transfer_time) <= path[v][0]): # same logic as before but making sure that we keep some time (transfer_time) between the two connections\n",
    "                if (t > path[u][0]):\n",
    "                    delay_max = path[v][0] - (t + delta + transfer_time)  # maximum delay time\n",
    "                    proba_delay = delay_proba(delay_max.seconds // 60 % 60, t + delta, vehicule, v) # computing the probability to make the connection based on this maximum delay time\n",
    "                    proba_success = 1 - proba_delay\n",
    "                    if (proba_success*path[v][4] > proba_threshold/100): #updating the path if the probability is sufficiently high\n",
    "                        path[u][0] = t\n",
    "                        path[u][1] = t + delta\n",
    "                        path[u][2] = v\n",
    "                        path[u][3] = trip_id\n",
    "                        path[u][4] = proba_success*path[v][4]\n",
    "                        path[u][5] = vehicule\n",
    "        \n",
    "        progress_bar.update(1)\n",
    "        \n",
    "    progress_bar.close()\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbef0904-8710-4625-b14e-360dd9b95189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilities\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "import pickle\n",
    "\n",
    "# loading models\n",
    "with open(f'../models/transport_type_ohe.pkl','rb') as f:\n",
    "    transport_type_ohe = pickle.load(f)\n",
    "\n",
    "with open(f'../models/stop_id_ohe.pkl','rb') as f:\n",
    "    stop_id_ohe = pickle.load(f)\n",
    "\n",
    "with open(f'../models/scaler.pkl','rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "with open(f'../models/log.pkl','rb') as f:\n",
    "    log = pickle.load(f)\n",
    "\n",
    "# Give the bin for the delay\n",
    "def label_bin(x):\n",
    "    bins = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30]\n",
    "    bins_id = range(len(bins) + 1)\n",
    "    for i, b in enumerate(bins):\n",
    "        if x <= b:\n",
    "            return bins_id[i]\n",
    "    return bins_id[-1]\n",
    "\n",
    "def delay_proba(delay_max, arrival_time_shedule, transport_type, stop_id):\n",
    "        \n",
    "    try:\n",
    "        df = pd.DataFrame(columns=['arrival_time_shedule', 'transport_type', 'stop_id'])\n",
    "        df.loc[0] = [arrival_time_shedule, str(transport_type), str(stop_id)]\n",
    "\n",
    "        df.arrival_time_shedule = pd.to_datetime(df.arrival_time_shedule, format='%d.%m.%Y %H:%M')\n",
    "\n",
    "        # Compute the predictors\n",
    "        df[\"minute\"] = df.arrival_time_shedule.dt.minute\n",
    "        df[\"hour\"] = df.arrival_time_shedule.dt.hour\n",
    "        df[\"month\"] = df.arrival_time_shedule.dt.month\n",
    "        df[\"year\"] = df.arrival_time_shedule.dt.year\n",
    "        df[\"week_of_year\"] = df.arrival_time_shedule.dt.isocalendar().week\n",
    "        df[\"day_of_year\"] = df.arrival_time_shedule.dt.day_of_year\n",
    "        df[\"day_of_week\"] = df.arrival_time_shedule.dt.day_of_week\n",
    "\n",
    "        inputCols = [\"minute\", \"hour\", \"month\", \"year\", \"week_of_year\", \"day_of_year\", \"day_of_week\"]\n",
    "        ohe_cols = [\"transport_type\", \"stop_id\"]\n",
    "        X = df[inputCols].to_numpy(dtype=int)\n",
    "        \n",
    "        # Scale data\n",
    "        X = scaler.transform(X)\n",
    "        \n",
    "        # One hot encode transport type\n",
    "        transformed = transport_type_ohe.transform(df[[ohe_cols[0]]])\n",
    "        X = hstack((X, transformed), format='csr')\n",
    "\n",
    "        # One hot encode stop id\n",
    "        transformed = stop_id_ohe.transform(df[[ohe_cols[1]]])\n",
    "        X = hstack((X, transformed), format='csr')\n",
    "\n",
    "        # Prediect the probability distribution\n",
    "        prob = log.predict_proba(X)[0]\n",
    "\n",
    "        # Get the delay bin\n",
    "        delay_bin = label_bin(delay_max)\n",
    "\n",
    "        # The probability of arrival time below delay_max is the sum of the prediected probability for delay <= delay_max\n",
    "        total_proba = sum(prob[:delay_bin + 1])\n",
    "\n",
    "        return total_proba\n",
    "    \n",
    "    # If the model fail for some raison\n",
    "    except:\n",
    "        return min(0.99 ** (10 - delay_max), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9a3b37-1222-4d46-ae7b-9693c3f78c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple\n",
    "delay_proba(5, '02.01.2022 15:30', 'Zug', '8503006')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6bf9fa-bb18-43b3-80f1-f37f05060608",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = routing(df_graph, DESTINATION, ARRIVAL_TIME, PROBA_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb20a961-3308-4906-b9c3-48643632043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_good = pd.DataFrame.from_dict(path, orient='index', dtype=None, columns=['departure_time','arrival_time','destination','trip_id','proba', 'vehicule'])\n",
    "path_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539055a3-6bc9-423d-a740-cdbbbbbcd50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_good.dropna(subset = ['destination', 'trip_id'], inplace=True)  # => PAS NORMAL D AVOIR DES TRIP_ID NONE => à checker, commande en attendant\n",
    "path_good['departure_time'] = path_good['departure_time'].apply(lambda x: x.time())\n",
    "path_good['arrival_time'] = path_good['arrival_time'].apply(lambda x: x.time())\n",
    "#path_good = path_good[path_good['destination'] is not None]\n",
    "path_good.sort_values(by = ['departure_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5ff82a-a88e-4137-968b-9d12e300345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the final path to follow\n",
    "\n",
    "final_path = [[DEPARTURE, path_good.loc[DEPARTURE].departure_time, path_good.loc[DEPARTURE].arrival_time, path_good.loc[DEPARTURE].destination, path_good.loc[DEPARTURE].trip_id, path_good.loc[DEPARTURE].vehicule]]\n",
    "destination = path_good.loc[DEPARTURE].destination\n",
    "\n",
    "for i in range(len(path_good)):\n",
    "    try:\n",
    "        final_path.append([destination, path_good.loc[destination].departure_time, path_good.loc[destination].arrival_time, path_good.loc[destination].destination, path_good.loc[destination].trip_id, path_good.loc[DEPARTURE].vehicule])\n",
    "        destination = path_good.loc[destination].destination\n",
    "    except:\n",
    "        print(\"There is no path available to go to the final destination. This is the beginning of the path:\")\n",
    "        break\n",
    "\n",
    "df_final_path = pd.DataFrame(final_path, columns=['departure', 'departure_time', 'arrival_time', 'destination', 'trip_id', 'vehicule'])\n",
    "df_final_path.groupby(['trip_id', 'vehicule']).agg(list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
